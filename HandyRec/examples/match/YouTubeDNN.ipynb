{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from handyrec.examples.utils import DataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from handyrec.models.match import YouTubeDNN\n",
    "from handyrec.features import DenseFeature, SparseFeature, SparseSeqFeature\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 128\n",
    "SEQ_LEN = 40\n",
    "BATCH_SIZE = 2**12\n",
    "NEPOCH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataProcessor('./ml-1m/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encode User Sparse Feats: 100%|██████████| 4/4 [00:00<00:00, 235.30it/s]\n",
      "Encode Item Sparse Feats: 0it [00:00, ?it/s]\n",
      "Generate train set: 100%|██████████| 6040/6040 [00:08<00:00, 710.82it/s] \n",
      "100%|██████████| 4/4 [00:00<00:00,  8.07it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "features = ['user_id', 'movie_id', 'gender', 'age', 'occupation', 'zip']\n",
    "lbd_features = ['gender','age','occupation', 'zip']\n",
    "data = dp.preprocess_data(lbd_features)\n",
    "dp.gen_data_set(features, data, seq_max_len=SEQ_LEN, negnum=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load user Features: 100%|██████████| 7/7 [00:00<00:00, 79.05it/s]\n",
      "Load movie Features: 100%|██████████| 1/1 [00:00<00:00, 500.22it/s]\n"
     ]
    }
   ],
   "source": [
    "user_features = ['user_id','gender','age','occupation', 'zip']\n",
    "movie_features = ['movie_id']\n",
    "train, train_label, test, test_label = dp.load_dataset(user_features, movie_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dim = {}\n",
    "for feat in user_features:\n",
    "    feature_dim[feat] = data['user'][feat].max()+1\n",
    "for feat in movie_features:\n",
    "    feature_dim[feat] = data['item'][feat].max()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dense_feats = []\n",
    "user_sparse_feats = ['user_id','gender','age','occupation', 'zip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features = [SparseFeature(x, feature_dim[x], EMBEDDING_DIM) for x in user_sparse_feats] +\\\n",
    "                [DenseFeature(x) for x in user_dense_feats] +\\\n",
    "                [SparseSeqFeature(SparseFeature('movie_id', feature_dim['movie_id'], EMBEDDING_DIM), 'hist_movie_id',SEQ_LEN)]\n",
    "item_id = SparseFeature('movie_id', feature_dim['movie_id'], EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "def sampledsoftmaxloss(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YouTubeDNN(\n",
    "    user_features, item_id, num_sampled=5, \n",
    "    user_dnn_hidden_units=(256,128,EMBEDDING_DIM), dnn_dropout=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 845828 samples, validate on 93981 samples\n",
      "Epoch 1/100\n",
      "845828/845828 [==============================] - 17s 20us/sample - loss: 0.8946 - val_loss: 0.8324\n",
      "Epoch 2/100\n",
      "845828/845828 [==============================] - 11s 13us/sample - loss: 0.6325 - val_loss: 0.5358\n",
      "Epoch 3/100\n",
      "845828/845828 [==============================] - 11s 13us/sample - loss: 0.5288 - val_loss: 0.5758\n",
      "Epoch 4/100\n",
      "845828/845828 [==============================] - 11s 13us/sample - loss: 0.4944 - val_loss: 0.3788\n",
      "Epoch 5/100\n",
      "845828/845828 [==============================] - 11s 13us/sample - loss: 0.5010 - val_loss: 0.5052\n",
      "Epoch 6/100\n",
      "845828/845828 [==============================] - 11s 13us/sample - loss: 0.4652 - val_loss: 0.4280\n",
      "Epoch 7/100\n",
      "845828/845828 [==============================] - 11s 13us/sample - loss: 0.5058 - val_loss: 0.4796\n",
      "Epoch 8/100\n",
      "845828/845828 [==============================] - 11s 13us/sample - loss: 0.4807 - val_loss: 0.4814\n",
      "Epoch 9/100\n",
      "845828/845828 [==============================] - 11s 13us/sample - loss: 0.4545 - val_loss: 0.5780\n",
      "Epoch 10/100\n",
      "845828/845828 [==============================] - 11s 14us/sample - loss: 0.4803 - val_loss: 0.4895\n",
      "Epoch 11/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.4237 - val_loss: 0.4469\n",
      "Epoch 12/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.4201 - val_loss: 0.3126\n",
      "Epoch 13/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.4369 - val_loss: 0.4910\n",
      "Epoch 14/100\n",
      "845828/845828 [==============================] - 11s 14us/sample - loss: 0.3878 - val_loss: 0.2799\n",
      "Epoch 15/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.4119 - val_loss: 0.3418\n",
      "Epoch 16/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3766 - val_loss: 0.4429\n",
      "Epoch 17/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.4029 - val_loss: 0.4052\n",
      "Epoch 18/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.4126 - val_loss: 0.2661\n",
      "Epoch 19/100\n",
      "845828/845828 [==============================] - 12s 15us/sample - loss: 0.3459 - val_loss: 0.4979A: 0s - loss: 0.345\n",
      "Epoch 20/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.4067 - val_loss: 0.4274\n",
      "Epoch 21/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3983 - val_loss: 0.3387\n",
      "Epoch 22/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3879 - val_loss: 0.4477\n",
      "Epoch 23/100\n",
      "845828/845828 [==============================] - 12s 15us/sample - loss: 0.3935 - val_loss: 0.3145\n",
      "Epoch 24/100\n",
      "845828/845828 [==============================] - 13s 15us/sample - loss: 0.3587 - val_loss: 0.3617\n",
      "Epoch 25/100\n",
      "845828/845828 [==============================] - 13s 15us/sample - loss: 0.3330 - val_loss: 0.4530\n",
      "Epoch 26/100\n",
      "845828/845828 [==============================] - 13s 15us/sample - loss: 0.3656 - val_loss: 0.4305\n",
      "Epoch 27/100\n",
      "845828/845828 [==============================] - 13s 15us/sample - loss: 0.3690 - val_loss: 0.3404\n",
      "Epoch 28/100\n",
      "845828/845828 [==============================] - 13s 15us/sample - loss: 0.3535 - val_loss: 0.3410A: 4s - loss: - ETA - ETA: 1s - loss:  - ETA: 0s - \n",
      "Epoch 29/100\n",
      "845828/845828 [==============================] - 13s 16us/sample - loss: 0.3597 - val_loss: 0.3931A: 0s - los\n",
      "Epoch 30/100\n",
      "845828/845828 [==============================] - 13s 15us/sample - loss: 0.3247 - val_loss: 0.3796\n",
      "Epoch 31/100\n",
      "845828/845828 [==============================] - 13s 16us/sample - loss: 0.3473 - val_loss: 0.3847 - los\n",
      "Epoch 32/100\n",
      "845828/845828 [==============================] - 13s 15us/sample - loss: 0.3500 - val_loss: 0.4006\n",
      "Epoch 33/100\n",
      "845828/845828 [==============================] - 13s 15us/sample - loss: 0.3067 - val_loss: 0.3487\n",
      "Epoch 34/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3312 - val_loss: 0.3133\n",
      "Epoch 35/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3057 - val_loss: 0.3120\n",
      "Epoch 36/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3213 - val_loss: 0.4401\n",
      "Epoch 37/100\n",
      "845828/845828 [==============================] - 13s 15us/sample - loss: 0.3253 - val_loss: 0.2455\n",
      "Epoch 38/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3679 - val_loss: 0.2911\n",
      "Epoch 39/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3090 - val_loss: 0.3543\n",
      "Epoch 40/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3152 - val_loss: 0.2580\n",
      "Epoch 41/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3020 - val_loss: 0.3182\n",
      "Epoch 42/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3262 - val_loss: 0.3311\n",
      "Epoch 43/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3341 - val_loss: 0.3295\n",
      "Epoch 44/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3200 - val_loss: 0.2762\n",
      "Epoch 45/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3106 - val_loss: 0.3209\n",
      "Epoch 46/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3024 - val_loss: 0.3671\n",
      "Epoch 47/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2955 - val_loss: 0.3082\n",
      "Epoch 48/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3154 - val_loss: 0.3144\n",
      "Epoch 49/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3105 - val_loss: 0.3578\n",
      "Epoch 50/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2807 - val_loss: 0.2949\n",
      "Epoch 51/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3093 - val_loss: 0.3697\n",
      "Epoch 52/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2908 - val_loss: 0.3946\n",
      "Epoch 53/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3050 - val_loss: 0.2684\n",
      "Epoch 54/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3261 - val_loss: 0.2660\n",
      "Epoch 55/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3068 - val_loss: 0.2430\n",
      "Epoch 56/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3044 - val_loss: 0.2331\n",
      "Epoch 57/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2860 - val_loss: 0.2469\n",
      "Epoch 58/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2784 - val_loss: 0.2986\n",
      "Epoch 59/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3096 - val_loss: 0.3638\n",
      "Epoch 60/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2974 - val_loss: 0.3023\n",
      "Epoch 61/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2940 - val_loss: 0.3897\n",
      "Epoch 62/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3026 - val_loss: 0.3221\n",
      "Epoch 63/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2995 - val_loss: 0.3751\n",
      "Epoch 64/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2733 - val_loss: 0.3828\n",
      "Epoch 65/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3007 - val_loss: 0.2756\n",
      "Epoch 66/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2688 - val_loss: 0.3289\n",
      "Epoch 67/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2950 - val_loss: 0.2801\n",
      "Epoch 68/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2985 - val_loss: 0.2810\n",
      "Epoch 69/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3119 - val_loss: 0.3806\n",
      "Epoch 70/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2983 - val_loss: 0.3708\n",
      "Epoch 71/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2686 - val_loss: 0.2194\n",
      "Epoch 72/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2834 - val_loss: 0.3038\n",
      "Epoch 73/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2511 - val_loss: 0.2686\n",
      "Epoch 74/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3086 - val_loss: 0.2795\n",
      "Epoch 75/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2641 - val_loss: 0.3247\n",
      "Epoch 76/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2773 - val_loss: 0.3413\n",
      "Epoch 77/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2799 - val_loss: 0.2921\n",
      "Epoch 78/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2856 - val_loss: 0.2358\n",
      "Epoch 79/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.3014 - val_loss: 0.2787\n",
      "Epoch 80/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2760 - val_loss: 0.3113\n",
      "Epoch 81/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2614 - val_loss: 0.3039\n",
      "Epoch 82/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2559 - val_loss: 0.2825\n",
      "Epoch 83/100\n",
      "845828/845828 [==============================] - 12s 14us/sample - loss: 0.2987 - val_loss: 0.3659\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"Adam\", loss=sampledsoftmaxloss)\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
    "history = model.fit(train, train_label,\n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    epochs=NEPOCH,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[early_stop])\n",
    "model.save_weights('youtubednn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('youtubednn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6040, 128)\n",
      "(3883, 128)\n"
     ]
    }
   ],
   "source": [
    "# 4. Generate user features for testing and full item features for retrieval\n",
    "all_item_model_input = {\"movie_id\": data['item']['movie_id'].values}\n",
    "\n",
    "user_embedding_model = Model(inputs=model.user_input, outputs=model.user_embedding)\n",
    "item_embedding_model = Model(inputs=model.item_input, outputs=model.item_embedding)\n",
    "\n",
    "user_embs = user_embedding_model.predict(test, batch_size=2 ** 12)\n",
    "item_embs = item_embedding_model.predict(all_item_model_input, batch_size=2 ** 12)\n",
    "\n",
    "print(user_embs.shape)\n",
    "print(item_embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.IndexFlatIP(EMBEDDING_DIM)\n",
    "index.add(item_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "D, I = index.search(np.ascontiguousarray(user_embs), 10)\n",
    "s = []\n",
    "for i, uid in enumerate(test['user_id']):\n",
    "    try:\n",
    "        pred = data['item']['movie_id'].values[I[i]].tolist()\n",
    "        s.append(pred)\n",
    "    except:\n",
    "        print(i)\n",
    "s = np.array(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "    for i, p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i + 1.0)\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=12):\n",
    "    return np.mean(\n",
    "        [apk(a, p, k) for a, p in zip(actual, predicted)]\n",
    "    )\n",
    "\n",
    "\n",
    "def rk(actual, predicted, k=10):\n",
    "    if len(predicted) > k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = sum([1 for r in actual if r in predicted])/len(actual)\n",
    "\n",
    "    return score\n",
    "\n",
    "def recall_at_k(actual, predicted, k=12):\n",
    "    return np.mean(\n",
    "        [rk(a, p, k) for a, p in zip(actual, predicted)]\n",
    "    )  # CHANGES: ignore null actual (variable=a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01860089482812993"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapk(test_label, s, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.050711920529801315"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_at_k(test_label, s, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "653a9876bfda977334bab0c6eac4e690c97044cb3c76993a10b084536ae29e50"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
